{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12501/12501 [02:31<00:00, 82.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 12501/12501 [02:27<00:00, 84.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"D:\\ML\\PetImages\"\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "IMG_SIZE = 50\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            \n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24946, 50, 50, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  6],\n",
       "        [  3],\n",
       "        [  9],\n",
       "        ...,\n",
       "        [ 43],\n",
       "        [ 42],\n",
       "        [ 42]],\n",
       "\n",
       "       [[  8],\n",
       "        [  4],\n",
       "        [  4],\n",
       "        ...,\n",
       "        [ 43],\n",
       "        [ 42],\n",
       "        [ 41]],\n",
       "\n",
       "       [[  9],\n",
       "        [  2],\n",
       "        [  2],\n",
       "        ...,\n",
       "        [ 45],\n",
       "        [ 43],\n",
       "        [ 42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[118],\n",
       "        [148],\n",
       "        [186],\n",
       "        ...,\n",
       "        [ 29],\n",
       "        [ 24],\n",
       "        [ 26]],\n",
       "\n",
       "       [[148],\n",
       "        [187],\n",
       "        [179],\n",
       "        ...,\n",
       "        [ 25],\n",
       "        [ 25],\n",
       "        [ 37]],\n",
       "\n",
       "       [[166],\n",
       "        [187],\n",
       "        [188],\n",
       "        ...,\n",
       "        [ 27],\n",
       "        [ 25],\n",
       "        [ 22]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==1.15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 4s 6ms/step - loss: 0.6303 - accuracy: 0.6361 - val_loss: 0.6139 - val_accuracy: 0.6582\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.5345 - accuracy: 0.7367 - val_loss: 0.5310 - val_accuracy: 0.7408\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.4805 - accuracy: 0.7716 - val_loss: 0.4741 - val_accuracy: 0.7732\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.4505 - accuracy: 0.7919 - val_loss: 0.4705 - val_accuracy: 0.7757\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.4168 - accuracy: 0.8123 - val_loss: 0.4451 - val_accuracy: 0.7924\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.3882 - accuracy: 0.8252 - val_loss: 0.4506 - val_accuracy: 0.8012\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.3683 - accuracy: 0.8345 - val_loss: 0.4600 - val_accuracy: 0.7946\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.3346 - accuracy: 0.8534 - val_loss: 0.4511 - val_accuracy: 0.8060\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.3104 - accuracy: 0.8651 - val_loss: 0.4960 - val_accuracy: 0.7853\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 3s 6ms/step - loss: 0.2900 - accuracy: 0.8753 - val_loss: 0.4569 - val_accuracy: 0.8040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1acba9c4388>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "\n",
    "X = X/255.0 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -------------------\n",
      "absl-py                 0.9.0\n",
      "astor                   0.8.1\n",
      "astunparse              1.6.3\n",
      "attrs                   19.3.0\n",
      "backcall                0.2.0\n",
      "beautifulsoup4          4.9.0\n",
      "bleach                  3.1.5\n",
      "bs4                     0.0.1\n",
      "cachetools              4.1.1\n",
      "certifi                 2020.6.20\n",
      "chardet                 3.0.4\n",
      "cmake                   3.17.2\n",
      "colorama                0.4.3\n",
      "cycler                  0.10.0\n",
      "Cython                  0.29.20\n",
      "decorator               4.4.2\n",
      "defusedxml              0.6.0\n",
      "entrypoints             0.3\n",
      "face-recognition-models 0.3.0\n",
      "filelock                3.0.12\n",
      "Flask                   0.10.1\n",
      "gast                    0.3.3\n",
      "gdown                   3.11.1\n",
      "google-auth             1.18.0\n",
      "google-auth-oauthlib    0.4.1\n",
      "google-images-download  2.8.0\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.30.0\n",
      "h5py                    2.10.0\n",
      "idna                    2.10\n",
      "importlib-metadata      1.7.0\n",
      "ipykernel               5.3.0\n",
      "ipython                 7.16.1\n",
      "ipython-genutils        0.2.0\n",
      "itsdangerous            1.1.0\n",
      "jedi                    0.17.1\n",
      "Jinja2                  2.11.2\n",
      "joblib                  0.15.1\n",
      "jsonschema              3.2.0\n",
      "jupyter-client          6.1.3\n",
      "jupyter-core            4.6.3\n",
      "Keras-Applications      1.0.8\n",
      "Keras-Preprocessing     1.1.2\n",
      "keras-resnet            0.1.0\n",
      "keras-retinanet         0.5.1\n",
      "kiwisolver              1.2.0\n",
      "lxml                    4.5.0\n",
      "Markdown                3.2.2\n",
      "MarkupSafe              1.1.1\n",
      "matplotlib              3.1.3\n",
      "mistune                 0.8.4\n",
      "mkl-fft                 1.1.0\n",
      "mkl-random              1.1.1\n",
      "mkl-service             2.3.0\n",
      "mplfinance              0.12.4a0\n",
      "mtcnn                   0.1.0\n",
      "nbconvert               5.6.1\n",
      "nbformat                5.0.7\n",
      "nltk                    3.4.5\n",
      "notebook                6.0.3\n",
      "numpy                   1.18.5\n",
      "oauthlib                3.1.0\n",
      "opencv-python           4.2.0.34\n",
      "opt-einsum              3.2.1\n",
      "packaging               20.4\n",
      "pandas                  1.0.1\n",
      "pandas-datareader       0.8.1\n",
      "pandocfilters           1.4.2\n",
      "parso                   0.7.0\n",
      "passlib                 1.6.2\n",
      "pickleshare             0.7.5\n",
      "Pillow                  7.0.0\n",
      "pip                     20.1.1\n",
      "progressbar2            3.51.4\n",
      "prometheus-client       0.8.0\n",
      "prompt-toolkit          3.0.5\n",
      "protobuf                3.12.2\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "Pygments                2.6.1\n",
      "pyparsing               2.4.7\n",
      "pyrsistent              0.16.0\n",
      "python-dateutil         2.8.1\n",
      "python-utils            2.4.0\n",
      "pytz                    2020.1\n",
      "pywin32                 227\n",
      "pywinpty                0.5.7\n",
      "pyzmq                   19.0.1\n",
      "requests                2.24.0\n",
      "requests-oauthlib       1.3.0\n",
      "rsa                     4.6\n",
      "scikit-learn            0.22.1\n",
      "scipy                   1.4.1\n",
      "seaborn                 0.10.0\n",
      "selenium                3.141.0\n",
      "Send2Trash              1.5.0\n",
      "setuptools              47.3.1.post20200622\n",
      "six                     1.15.0\n",
      "soupsieve               2.0\n",
      "tensorboard             2.2.2\n",
      "tensorboard-plugin-wit  1.7.0\n",
      "tensorflow              2.2.0\n",
      "tensorflow-estimator    2.2.0\n",
      "tensorflow-gpu          2.0.0\n",
      "termcolor               1.1.0\n",
      "terminado               0.8.3\n",
      "testpath                0.4.4\n",
      "tflearn                 0.3.2\n",
      "tornado                 6.0.4\n",
      "tqdm                    4.42.1\n",
      "traitlets               4.3.3\n",
      "urllib3                 1.25.9\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "Werkzeug                1.0.1\n",
      "wheel                   0.34.2\n",
      "wikipedia               1.4.0\n",
      "wincertstore            0.2\n",
      "wrapt                   1.12.1\n",
      "zipp                    3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: dogs vs cats (model_2)\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('dogs vs cats (model_2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loaded_model = tf.keras.models.load_model('tf_lite.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = [\"Dog\", \"Cat\"]  # will use this to convert prediction num to string value\n",
    "import cv2\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # return the image with shaping that TF wants.\n",
    "inputs = prepare(r'C:\\Users\\Gaming\\Jupyter Notebook\\Test Images\\1.jpg')\n",
    "prediction = loaded_model.predict(inputs)  # REMEMBER YOU'RE PASSING A LIST OF THINGS YOU WISH TO PREDICT\n",
    "\n",
    "# prediction\n",
    "\n",
    "if prediction == 0:\n",
    "    predict = 'dog'\n",
    "else:\n",
    "    predict = 'cat'\n",
    "\n",
    "print(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
